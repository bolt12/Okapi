{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualifier\n",
    "\n",
    "+ Qualifica um outfit, atribuindo-lhe um score.\n",
    "\n",
    "+ **Input**: Embedding das peças\n",
    "+ **Output**: Score do outfit\n",
    "\n",
    "Desenvolvida uma CNN básica com multi-input e single output. O objetivo desta rede é o de obter algo para conseguir criar o serviço do sugestor. Maior desenvolvimento é necessário para obter resultados utilizáveis.\n",
    "\n",
    "A rede foi treinada com o dataset de outfits do Polyvore.\n",
    "\n",
    "**Dataset**: https://drive.google.com/file/d/0B4Eo9mft9jwoNm5WR3ltVkJWX0k/view?usp=sharing\n",
    "\n",
    "**Features**: nomes das imagens correspondentes a outfits. Os nomes são construidos da seguinte maneira \"outfit\"_\"artigo\"\n",
    "\n",
    "**Labels**: 0 -> Caso o conjunto de artigos não componha um outfit\n",
    "        1 -> Caso contrário\n",
    "        \n",
    "Os pesos da rede desenvolvida estão armazenados em prototype_cnn.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = \"../../datasets/Polyvore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df = pd.read_csv(dataset_path+\"/fashion_compatibility_prediction.txt\",\n",
    "                             sep=' ',\n",
    "                             header=None,\n",
    "                              names=['label','item_1','item_2','item_3','item_4','item_5','item_6','item_7','item_8'],\n",
    "                            keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size:\", fashion_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePath(image_name):\n",
    "    if image_name != '':\n",
    "        name = image_name.split(\"_\")\n",
    "        return dataset_path + \"/images/\"+name[0]+\"/\"+name[1]+\".jpg\"\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(image_path):\n",
    "    #print(image_path)\n",
    "    if image_path != '':\n",
    "        bgr_img = cv2.imread(image_path)\n",
    "        bgr_img = cv2.resize(bgr_img, (400,400))\n",
    "    else:\n",
    "        bgr_img = np.zeros((400,400, 3), dtype=\"uint8\")\n",
    "    return bgr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showOutfit(outfit):\n",
    "    count = 0\n",
    "    items = list()\n",
    "    for item in outfit:\n",
    "        if item != '':\n",
    "            count += 1\n",
    "            item_path = getImagePath(item)\n",
    "            items.append(item_path)\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    for i in range(count):\n",
    "        ax = fig.add_subplot(1,count, i+1, xticks=[], yticks=[])\n",
    "        image = loadImage(items[i])\n",
    "        print('Image size:', image.shape)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title('item %s' % (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image:\",fashion_df.iloc[1,2])\n",
    "print(\"at:\", getImagePath(fashion_df.iloc[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOutfit(fashion_df.iloc[1, 1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fashion_df = fashion_df[0:500]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    fashion_df.iloc[:, 1 : 5], \n",
    "    fashion_df.iloc[:, 0], test_size=0.20,\n",
    "    random_state=42)\n",
    "\n",
    "X_train = X_train[0:500]\n",
    "y_train = y_train[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_images = X_train.applymap(getImagePath)\n",
    "X_train_images = X_train_images.applymap(loadImage)\n",
    "X_train_images = np.array(X_train_images)\n",
    "X_train_images = X_train_images / 255.0\n",
    "\n",
    "X_test_images = X_test.applymap(getImagePath)\n",
    "X_test_images = X_test_images.applymap(loadImage)\n",
    "X_test_images = np.array(X_test_images)\n",
    "X_test_images = X_test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrapArray(array, new_shape):\n",
    "    unwrapped_array = np.zeros(new_shape)\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array[0].shape[0]):\n",
    "            unwrapped_array[i,j,:,:,:] = array[i,j]\n",
    "    return unwrapped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = unwrapArray(X_train_images, (X_train_images.shape[0],X_train_images.shape[1],64,64,3))\n",
    "x_test_array = unwrapArray(X_test_images, (X_test_images.shape[0],X_test_images.shape[1],64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = x_train_array.transpose(1,0,2,3,4)\n",
    "x_test_array = x_test_array.transpose(1,0,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    image = Input(shape=(64,64,3))\n",
    "    \n",
    "    chanDim = -1\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding=\"same\")(image)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    model = Model(inputs = image, outputs = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = build_cnn()\n",
    "model_2 = build_cnn()\n",
    "model_3 = build_cnn()\n",
    "model_4 = build_cnn()\n",
    "\n",
    "combinedInput = concatenate([model_1.output, model_2.output, model_3.output, model_4.output])\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(combinedInput)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=[model_1.input, model_2.input, model_3.input, model_4.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    [x_train_array[0], x_train_array[1], x_train_array[2], x_train_array[3]], y_train,\n",
    "    epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate([x_test_array[0],x_test_array[1],x_test_array[2],x_test_array[3]], y_test, verbose = False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('prototype_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
